{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employment Claims and Housing Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up necessary packagaes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Price Data\n",
    "Load Housing Data from file and pre-process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_zHousing_df = pd.read_csv('State_Zhvi_AllHomes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zHousing_df = raw_zHousing_df.drop(['RegionID','RegionType','StateName', 'SizeRank'], axis = 1)\n",
    "zHousing_df = zHousing_df.set_index(['RegionName'])\n",
    "zHousing_df = zHousing_df.T\n",
    "zHousing_df['Date'] = pd.to_datetime(zHousing_df.index)\n",
    "#zHousing_df['month'] = zHousing_df['Date'].dt.month\n",
    "zHousing_df['year'] = zHousing_df['Date'].dt.year\n",
    "zHousing_df['week'] = zHousing_df['Date'].dt.week\n",
    "zHousing_df = zHousing_df.set_index(['year','week'])\n",
    "\n",
    "zHousing_df = zHousing_df.drop(['Date'], axis=1)\n",
    "#zHousing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for individual counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cityHousing_df = pd.read_csv('City_Zhvi_AllHomes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_countyHP_df = raw_cityHousing_df.drop(['RegionID','RegionType','RegionName', 'SizeRank','Metro','State'], axis = 1)\n",
    "\n",
    "# get full state name from state housing price datafile\n",
    "state_abbrvMap = raw_zHousing_df[['StateName','RegionName']]\n",
    "countyHP_df = pd.merge(tmp_countyHP_df, state_abbrvMap, how='left', left_on='StateName', right_on='StateName')\n",
    "countyHP_df = countyHP_df.drop(['StateName'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CountyPrices(State):\n",
    "    \n",
    "    df = countyHP_df[countyHP_df['RegionName'] == State]\n",
    "    df = df.drop(['RegionName'], axis=1)\n",
    "    \n",
    "    df = df.set_index(['CountyName'])\n",
    "    df = df.T\n",
    "    df['Date'] = pd.to_datetime(df.index)\n",
    "    df['week'] = df['Date'].dt.week\n",
    "    df['year'] = df['Date'].dt.year\n",
    "    df = df.set_index(['year','week'])\n",
    "    \n",
    "    df = df.drop(['Date'], axis=1)\n",
    "    \n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#get_CountyPrices('Michigan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insurance Claims Data\n",
    "\n",
    "Pre-process the insurance claims data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_Uinsurance_df = pd.read_csv('r539cy-master.xls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uinsurance_df = raw_Uinsurance_df\n",
    "Uinsurance_df['Date'] = pd.to_datetime(raw_Uinsurance_df['Filed week ended'])\n",
    "#Uinsurance_df['month'] = Uinsurance_df['Date'].dt.month\n",
    "Uinsurance_df['year'] = Uinsurance_df['Date'].dt.year\n",
    "Uinsurance_df['week'] = Uinsurance_df['Date'].dt.week\n",
    "\n",
    "Uinsurance_df = Uinsurance_df.drop(['Date'], axis=1)\n",
    "# drop the records before 1996, to match the data  that is available from Zillow\n",
    "Uinsurance_df = Uinsurance_df[Uinsurance_df['year'] > 1995]\n",
    "\n",
    "Uinsurance_df['Initial Claims'] = Uinsurance_df['Initial Claims'].str.replace(',', '').astype(int)\n",
    "Uinsurance_df['Continued Claims'] = Uinsurance_df['Continued Claims'].str.replace(',', '').astype(int)\n",
    "Uinsurance_df['Covered Employment'] = Uinsurance_df['Covered Employment'].str.replace(',', '').astype(int)\n",
    "\n",
    "#Uinsurance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform unemployment insurance data into format that can be merged with the housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_initclaims_df = pd.pivot_table(Uinsurance_df, values='Initial Claims', index=['year', 'week'], columns=['State'], aggfunc=np.sum)\n",
    "ui_contclaims_df = pd.pivot_table(Uinsurance_df, values='Continued Claims', index=['year', 'week'], columns=['State'], aggfunc=np.sum)\n",
    "ui_rate_df = pd.pivot_table(Uinsurance_df, values='Insured Unemployment Rate', index=['year', 'week'], columns=['State'], aggfunc=np.mean)\n",
    "ui_covEmp_df = pd.pivot_table(Uinsurance_df, values='Covered Employment', index=['year', 'week'], columns=['State'], aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Data\n",
    "Combine UI and Housing Price data for each State into DataFrame and Engineer training featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_State_df (stateName):    \n",
    "    \n",
    "    tmp_sHousing_df = zHousing_df[stateName]\n",
    "    \n",
    "    df = pd.DataFrame([])\n",
    "    df['Initial Claims'] = ui_initclaims_df[stateName]\n",
    "    df['Continued Claims'] = ui_contclaims_df[stateName]\n",
    "    df['Covered Employment'] = ui_covEmp_df[stateName]\n",
    "    df['Insured Unemployment Rate'] = ui_rate_df[stateName]\n",
    "    \n",
    "    df = pd.merge(df, tmp_sHousing_df, how='left', left_index=True, right_index=True)\n",
    "    #df = pd.merge(df, tmp_sHousing_df, how='inner', left_index=True, right_index=True)\n",
    "    df[stateName].fillna(method='ffill', inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    df['housingTarget'] = round(df[stateName].astype(int) / 1000, 1)\n",
    "    \n",
    "    # Marginally better result with county data\n",
    "    #county_df = get_CountyPrices(stateName)\n",
    "    #df = pd.merge(df, county_df, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    tmp_arr = []\n",
    "    if stateName in df.columns:\n",
    "        df.sort_index(ascending=True, inplace=True)\n",
    "        df = df.reset_index()\n",
    "\n",
    "        df.fillna(0, inplace=True)        \n",
    "        df['PrevHousePrc'] = df['housingTarget'].rolling(2, min_periods=1).sum() - df['housingTarget']\n",
    "        df['MvngAvgPrc15'] = round(df['PrevHousePrc'].rolling(10).mean())\n",
    "        df['MvngAvgPrc30'] = round(df['PrevHousePrc'].rolling(15).mean())    \n",
    "        #df['PercentChnge'] = round((df['housingTarget'] - df['PrevHousePrc']) / (df['PrevHousePrc'] + .1), 4) * 1000\n",
    "        \n",
    "        df = df.drop([stateName], axis=1)\n",
    "        \n",
    "        \n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    df = df.iloc[1:]  \n",
    "    test_df = df.tail(1)\n",
    "    df.drop(df.tail(1).index, inplace=True)\n",
    "    \n",
    "    \n",
    "    return df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>Initial Claims</th>\n",
       "      <th>Continued Claims</th>\n",
       "      <th>Covered Employment</th>\n",
       "      <th>Insured Unemployment Rate</th>\n",
       "      <th>housingTarget</th>\n",
       "      <th>PrevHousePrc</th>\n",
       "      <th>MvngAvgPrc15</th>\n",
       "      <th>MvngAvgPrc30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>2020</td>\n",
       "      <td>15</td>\n",
       "      <td>222207</td>\n",
       "      <td>749011</td>\n",
       "      <td>4305711</td>\n",
       "      <td>17.4</td>\n",
       "      <td>177.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  week  Initial Claims  Continued Claims  Covered Employment  \\\n",
       "1264  2020    15          222207            749011             4305711   \n",
       "\n",
       "      Insured Unemployment Rate  housingTarget  PrevHousePrc  MvngAvgPrc15  \\\n",
       "1264                       17.4          177.0         177.0         176.0   \n",
       "\n",
       "      MvngAvgPrc30  \n",
       "1264         175.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, test_df = get_State_df ('Michigan')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Test Function\n",
    "Test how strongly the values are co-related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_State_Prop (df):\n",
    "    \n",
    "    fin_r = stats.ttest_ind(df['Initial Claims'], df['housingTarget'], equal_var=False)\n",
    "    return fin_r[0], fin_r[1], len(df['housingTarget'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GBT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_StateModels():\n",
    "\n",
    "    state_Results = []    \n",
    "    offset = 1\n",
    "    \n",
    "    states = zHousing_df.columns\n",
    "    #states = ['Alaska','Michigan']\n",
    "    \n",
    "    for state in states:\n",
    "\n",
    "        df, f_test = get_State_df(state)\n",
    "        \n",
    "        # features\n",
    "        X = df[['Initial Claims','Continued Claims','Insured Unemployment Rate','Covered Employment','PrevHousePrc']]\n",
    "        # target\n",
    "        y = df[['housingTarget']]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "        #clf = DecisionTreeRegressor(learning_rate = 0.015, random_state = 42, max_depth = 2, n_estimators = 110)\n",
    "        clf = DecisionTreeRegressor(random_state = 42, max_depth = 4)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_predicted = clf.predict(f_test[['Initial Claims','Continued Claims','Insured Unemployment Rate','Covered Employment','PrevHousePrc']]) \n",
    "\n",
    "        #statistic, pvalue, unique_targets = get_State_Prop(X, y)\n",
    "        state_Results.append([state, clf.score(X_train, y_train), clf.score(X_test, y_test), \n",
    "                              #statistic, pvalue, unique_targets, \n",
    "                              y_predicted[0], f_test['housingTarget'].to_numpy()[0]])\n",
    "        \n",
    "    return state_Results\n",
    "\n",
    "#train_StateModels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Assessment for GBDT\n",
    "Call the grid search to identify which parameters work be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP CLassifier Model\n",
    "def train_StateMLPMdls():\n",
    "\n",
    "    state_Results = []\n",
    "    factor = 1 #5000\n",
    "    \n",
    "    states = sorted(zHousing_df.columns)\n",
    "    #states = ['Alaska','Michigan']\n",
    "    \n",
    "    for state in states:\n",
    "        \n",
    "        df, f_test = get_State_df(state)\n",
    "\n",
    "        X = df.drop(['housingTarget'], axis=1)\n",
    "        y = df[['housingTarget']]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        X_ftest_scaled = scaler.transform(X.iloc[-1:])\n",
    "                               \n",
    "        mlp_clf = MLPRegressor(hidden_layer_sizes = [100, 100], solver='lbfgs', alpha=0.15, random_state=42).fit(X_train_scaled, y_train)                \n",
    "        y_predicted = mlp_clf.predict(X_ftest_scaled) \n",
    "\n",
    "        #statistic, pvalue, unique_targets = get_State_Prop(X, y)\n",
    "        state_Results.append([state, mlp_clf.score(X_train_scaled, y_train), mlp_clf.score(X_test_scaled, y_test), \n",
    "                              #statistic, pvalue, unique_targets, \n",
    "                              y_predicted[0], f_test['housingTarget'].to_numpy()[0]])\n",
    "        \n",
    "    return state_Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9961994964809477"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_results(model):\n",
    "\n",
    "    if 'mlp' in model:\n",
    "        State_results_df = pd.DataFrame(train_StateMLPMdls())\n",
    "        #State_results_df.columns = ['State','Train Score', 'Test Score', 'Statistic', 'Pvalue', 'Unique Targets','Predicted', 'Actual']\n",
    "        State_results_df.to_csv('stateResults_mlp.csv', index=False)\n",
    "    else: \n",
    "        State_results_df = pd.DataFrame(train_StateModels())\n",
    "        #State_results_df.sort_values(by=['Test Score'], ascending=False, inplace=True)  \n",
    "        #State_results_df.columns = ['State','Train Score', 'Test Score', 'Statistic', 'Pvalue', 'Unique Targets','Predicted', 'Actual']\n",
    "        State_results_df.to_csv('stateResults_gbc.csv', index=False)\n",
    "    \n",
    "    return State_results_df[2].to_numpy().mean()\n",
    "    \n",
    "save_results('mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "GDP\n",
    "#https://apps.bea.gov/regional/Downloadzip.cfm\n",
    "#https://apps.bea.gov/itable/iTable.cfm?ReqID=70&step=1\n",
    "\n",
    "Unemployment\n",
    "#https://oui.doleta.gov/unemploy/claims_arch.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
